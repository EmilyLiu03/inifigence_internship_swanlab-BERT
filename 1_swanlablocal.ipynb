{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c85a56a",
   "metadata": {},
   "source": [
    "# 题目说明\n",
    "This is an explaination of my code.\n",
    " - 题目1：完成上述 SwanLab 教程，可以通过 SwanLab 网站查看实验数据  \n",
    " 实验数据和折线图如下图所示：  \n",
    " ![swablab_1.png](https://raw.githubusercontent.com/EmilyLiu03/inifigence_internship_swanlab-BERT/main/swablab_1.png)\n",
    " ![swanlab_2.png](https://raw.githubusercontent.com/EmilyLiu03/inifigence_internship_swanlab-BERT/main/swanlab_2.png)\n",
    " \n",
    " - 特殊说明  \n",
    " 由于SSH远程访问huggingface的datasets失败，代码模型的实现是基于本地进行的。题目1、2相同，后续不再赘述。  \n",
    " Github上，因为文件过大等原因，暂无数据集和本地模型，下载链接可直接访问：  \n",
    " [imdb/data](http://ai.stanford.edu/~amaas/data/sentiment/)  \n",
    " [BERT/model](https://huggingface.co/google-bert/bert-base-chinese)\n",
    "\n",
    " # 代码详情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, Dataset, DatasetDict, Features, Value, ClassLabel\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from swanlab.integration.transformers import SwanLabCallback\n",
    "import swanlab\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 定义加载本地IMDB数据集的函数\n",
    "def load_imdb_dataset(data_dir):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "\n",
    "    # 读取训练数据\n",
    "    for label in ['pos', 'neg']:\n",
    "        folder_path = os.path.join(data_dir, 'train', label)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.txt'):\n",
    "                with open(os.path.join(folder_path, file_name), 'r', encoding='utf-8') as file:\n",
    "                    train_data.append({'text': file.read(), 'label': 1 if label == 'pos' else 0})\n",
    "\n",
    "    # 读取测试数据\n",
    "    for label in ['pos', 'neg']:\n",
    "        folder_path = os.path.join(data_dir, 'test', label)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.txt'):\n",
    "                with open(os.path.join(folder_path, file_name), 'r', encoding='utf-8') as file:\n",
    "                    test_data.append({'text': file.read(), 'label': 1 if label == 'pos' else 0})\n",
    "\n",
    "    return DatasetDict({\n",
    "        'train': Dataset.from_pandas(pd.DataFrame(train_data)),\n",
    "        'test': Dataset.from_pandas(pd.DataFrame(test_data))\n",
    "    })\n",
    "\n",
    "# 加载本地IMDB数据集\n",
    "data_dir = '/root/aclImdb' \n",
    "dataset = load_imdb_dataset(data_dir)\n",
    "\n",
    "# 加载预训练的BERT tokenizer和模型\n",
    "model_path = '/root/bert-base-uncased' \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "\n",
    "# 定义tokenize函数\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "# 对数据集进行tokenization\n",
    "tokenized_datasets = dataset.map(tokenize, batched=True)\n",
    "\n",
    "# 设置模型输入格式\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# 设置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    logging_first_step=100,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "CLASS_NAME = {0: \"negative\", 1: \"positive\"}\n",
    "\n",
    "# 设置swanlab回调函数\n",
    "swanlab_callback = SwanLabCallback(project='BERT',\n",
    "                                   experiment_name='BERT-IMDB',\n",
    "                                   config={'dataset': 'IMDB', \"CLASS_NAME\": CLASS_NAME})\n",
    "\n",
    "# 定义Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    callbacks=[swanlab_callback],\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "trainer.train()\n",
    "\n",
    "# 保存模型\n",
    "model.save_pretrained('./sentiment_model')\n",
    "tokenizer.save_pretrained('./sentiment_model')\n",
    "\n",
    "# 测试模型\n",
    "test_reviews = [\n",
    "    \"I absolutely loved this movie! The storyline was captivating and the acting was top-notch. A must-watch for everyone.\",\n",
    "    \"This movie was a complete waste of time. The plot was predictable and the characters were poorly developed.\",\n",
    "    \"An excellent film with a heartwarming story. The performances were outstanding, especially the lead actor.\",\n",
    "    \"I found the movie to be quite boring. It dragged on and didn't really go anywhere. Not recommended.\",\n",
    "    \"A masterpiece! The director did an amazing job bringing this story to life. The visuals were stunning.\",\n",
    "    \"Terrible movie. The script was awful and the acting was even worse. I can't believe I sat through the whole thing.\",\n",
    "    \"A delightful film with a perfect mix of humor and drama. The cast was great and the dialogue was witty.\",\n",
    "    \"I was very disappointed with this movie. It had so much potential, but it just fell flat. The ending was particularly bad.\",\n",
    "    \"One of the best movies I've seen this year. The story was original and the performances were incredibly moving.\",\n",
    "    \"I didn't enjoy this movie at all. It was confusing and the pacing was off. Definitely not worth watching.\"\n",
    "]\n",
    "\n",
    "model.to('cpu')\n",
    "text_list = []\n",
    "for review in test_reviews:\n",
    "    label = predict(review, model, tokenizer, CLASS_NAME)\n",
    "    text_list.append(swanlab.Text(review, caption=f\"{label}-{CLASS_NAME[label]}\"))\n",
    "\n",
    "if text_list:\n",
    "    swanlab.log({\"predict\": text_list})\n",
    "\n",
    "swanlab.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
